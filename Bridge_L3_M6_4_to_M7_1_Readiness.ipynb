{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bridge L3.M6.4 → L3.M7.1 Readiness Validation\n",
    "## Security Complete → Observability Begins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Purpose\n",
    "\n",
    "Module 6.4 delivered enterprise security with audit trails, GDPR automation, and compliance logging through ELK and structured logging. Module 7.1 will shift from aggregate metrics to **request-level observability** using distributed tracing. This bridge validates that the security foundation is operational and metrics infrastructure is ready before adding trace instrumentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concepts Covered\n",
    "\n",
    "- **ELK Stack readiness**: Verifying Kibana and Elasticsearch audit event storage\n",
    "- **Structured logging validation**: Confirming request_id correlation across log types\n",
    "- **Prometheus metrics baseline**: Checking P50/P95 latency targets for trace comparison\n",
    "- **Security module verification**: Git commit evidence and functionality checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## After Completing\n",
    "\n",
    "- Verify ELK stack is operational with ≥100 audit events in the last 24 hours\n",
    "- Confirm structured logging includes request_id fields for correlation\n",
    "- Validate Grafana shows P50 (300-600ms) and P95 (700-1,200ms) baselines\n",
    "- Check M6.1-M6.4 commits exist and security features are functional\n",
    "- Understand the gap distributed tracing will fill (aggregate vs. per-request visibility)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Context in Track\n",
    "\n",
    "**Bridge L3.M6.4 → L3.M7.1**: Security Complete → Observability Begins\n",
    "\n",
    "This validation ensures the security and metrics infrastructure from Module 6 is operational before Module 7 adds OpenTelemetry tracing to diagnose per-request performance bottlenecks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Run Locally\n",
    "\n",
    "**Windows**:\n",
    "```powershell\n",
    "powershell -c \"$env:PYTHONPATH='$PWD'; jupyter notebook\"\n",
    "```\n",
    "\n",
    "**macOS/Linux**:\n",
    "```bash\n",
    "PYTHONPATH=$PWD jupyter notebook\n",
    "```\n",
    "\n",
    "**Note**: External services (Kibana, Grafana, Elasticsearch, Prometheus) are optional. Checks will skip gracefully if services are unavailable.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: M6.4 Delivery Recap\n",
    "\n",
    "Module 6.4 completed the **enterprise security foundation** with four major achievements:\n",
    "\n",
    "### 1. Comprehensive Audit Trail\n",
    "- **ELK Stack Implementation**: Captures WHO (user_id, role, IP), WHAT (action, resource), WHEN (timestamp), and outcome\n",
    "- **Tamper-Proof Storage**: Hash chaining for audit integrity\n",
    "- **Centralized Aggregation**: Elasticsearch for compliance queries\n",
    "\n",
    "### 2. GDPR Automation\n",
    "- **Efficiency Gain**: 40 hours manual work → 5 minutes automated\n",
    "- **Right-to-Erasure**: Automated across systems with audit proof\n",
    "- **Consent Tracking**: Linked to processing actions\n",
    "\n",
    "### 3. Retention Policies\n",
    "- **Tiered Storage**:\n",
    "  - Hot: 0-90 days (Elasticsearch)\n",
    "  - Warm: 90 days-1 year (S3)\n",
    "  - Cold: 1-7 years (Glacier)\n",
    "- **Automatic Deletion**: After retention periods\n",
    "\n",
    "### 4. Complete Security Stack\n",
    "- M6.1: PII redaction\n",
    "- M6.2: Secrets management\n",
    "- M6.3: RBAC\n",
    "- M6.4: Compliance auditing\n",
    "\n",
    "**Result**: Enterprise-grade security posture achieved.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Readiness Check #1 - ELK Stack Operational\n",
    "\n",
    "**Requirement**: Kibana accessible at localhost:5601 with audit-logs-* index showing events from last 24 hours; Elasticsearch query returns ≥100 events.\n",
    "\n",
    "**Pass Criteria**:\n",
    "- Kibana UI responds at http://localhost:5601\n",
    "- Index `audit-logs-*` exists\n",
    "- Event count ≥ 100 in last 24 hours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check ELK Stack\n",
    "\n",
    "This function verifies Kibana is accessible and Elasticsearch contains sufficient audit events. If services are unavailable, the check skips gracefully with a warning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "OFFLINE_MODE = False  # Set to True to skip all external service checks\n",
    "\n",
    "def check_elk_stack():\n",
    "    \"\"\"Verify Kibana accessibility and Elasticsearch audit event count.\"\"\"\n",
    "    if OFFLINE_MODE:\n",
    "        print(\"⚠️ Offline mode: Skipping ELK stack check\")\n",
    "        return\n",
    "    \n",
    "    # Check Kibana accessibility\n",
    "    try:\n",
    "        kibana_url = \"http://localhost:5601/api/status\"\n",
    "        resp = requests.get(kibana_url, timeout=5)\n",
    "        print(f\"✓ Kibana: {resp.status_code}\")\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Skipping (Kibana not available)\")\n",
    "        return\n",
    "    \n",
    "    # Check Elasticsearch index and event count\n",
    "    try:\n",
    "        es_url = \"http://localhost:9200/audit-logs-*/_count\"\n",
    "        query = {\"query\": {\"range\": {\"@timestamp\": {\"gte\": \"now-24h\"}}}}\n",
    "        resp = requests.post(es_url, json=query, timeout=5)\n",
    "        count = resp.json().get('count', 0)\n",
    "        status = \"✓\" if count >= 100 else \"✗\"\n",
    "        print(f\"{status} Events (24h): {count} (required: ≥100)\")\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Skipping (Elasticsearch not available)\")\n",
    "\n",
    "# Uncomment to run: check_elk_stack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Readiness Check #2 - Structured Logging\n",
    "\n",
    "**Requirement**: Application logs include unique `request_id` fields; correlation works between logs and audit events via request_id queries in Kibana.\n",
    "\n",
    "**Pass Criteria**:\n",
    "- Application logs contain `request_id` field\n",
    "- Correlation between logs and audit events via `request_id`\n",
    "- Kibana query can trace a request across both log types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Structured Logging\n",
    "\n",
    "This function searches Elasticsearch for logs containing request_id fields, confirming that correlation queries will work in Kibana for tracing requests across services."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_structured_logging():\n",
    "    \"\"\"Verify logs contain request_id for cross-service correlation.\"\"\"\n",
    "    if OFFLINE_MODE:\n",
    "        print(\"⚠️ Offline mode: Skipping structured logging check\")\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        es_url = \"http://localhost:9200/_search\"\n",
    "        query = {\n",
    "            \"size\": 1,\n",
    "            \"query\": {\"exists\": {\"field\": \"request_id\"}},\n",
    "            \"_source\": [\"request_id\", \"@timestamp\", \"message\"]\n",
    "        }\n",
    "        resp = requests.post(es_url, json=query, timeout=5)\n",
    "        hits = resp.json().get('hits', {}).get('hits', [])\n",
    "        \n",
    "        if hits:\n",
    "            req_id = hits[0]['_source'].get('request_id')\n",
    "            print(f\"✓ request_id found: {req_id[:16]}...\")\n",
    "            print(f\"✓ Correlation: Query Kibana with 'request_id:\\\"{req_id}\\\"'\")\n",
    "        else:\n",
    "            print(\"✗ No logs with request_id field found\")\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Skipping (Elasticsearch not available)\")\n",
    "\n",
    "# Uncomment to run: check_structured_logging()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4: Readiness Check #3 - Prometheus Metrics\n",
    "\n",
    "**Requirement**: Grafana dashboard at localhost:3000 updates every 15 seconds showing P50 (300-600ms baseline), P95 (700-1,200ms), request rates, and error rates <1%.\n",
    "\n",
    "**Pass Criteria**:\n",
    "- Grafana accessible at http://localhost:3000\n",
    "- Dashboard shows P50 latency: 300-600ms\n",
    "- Dashboard shows P95 latency: 700-1,200ms\n",
    "- Error rate < 1%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Prometheus Metrics\n",
    "\n",
    "This function verifies Grafana is accessible and displays the expected latency baseline queries. These metrics establish the pre-tracing performance baseline for comparison after M7.1 instrumentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_prometheus_metrics():\n",
    "    \"\"\"Verify Grafana accessibility and expected latency metric queries.\"\"\"\n",
    "    if OFFLINE_MODE:\n",
    "        print(\"⚠️ Offline mode: Skipping Prometheus metrics check\")\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        grafana_url = \"http://localhost:3000/api/health\"\n",
    "        resp = requests.get(grafana_url, timeout=5)\n",
    "        print(f\"✓ Grafana: {resp.status_code}\")\n",
    "        \n",
    "        # Display expected Prometheus queries for manual verification\n",
    "        print(\"✓ Expected metrics: P50=300-600ms, P95=700-1200ms, errors<1%\")\n",
    "        print(\"  P50 query: histogram_quantile(0.50, rate(http_request_duration_ms_bucket[5m]))\")\n",
    "        print(\"  P95 query: histogram_quantile(0.95, rate(http_request_duration_ms_bucket[5m]))\")\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Skipping (Grafana not available)\")\n",
    "\n",
    "# Uncomment to run: check_prometheus_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5: Readiness Check #4 - M6 Completion\n",
    "\n",
    "**Requirement**: GitHub repository contains commits for M6.1-M6.4; each module's functionality verified.\n",
    "\n",
    "**Pass Criteria**:\n",
    "- M6.1: PII detection functional\n",
    "- M6.2: Vault secrets management operational\n",
    "- M6.3: RBAC enforcement working\n",
    "- M6.4: Elasticsearch audit events present"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check M6 Module Completion\n",
    "\n",
    "This function searches git history for M6-related commits, providing evidence that security modules were completed. Manual verification of functionality is still required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "def check_m6_completion():\n",
    "    \"\"\"Verify git commits exist for M6.1-M6.4 security modules.\"\"\"\n",
    "    if OFFLINE_MODE:\n",
    "        print(\"⚠️ Offline mode: Skipping M6 completion check\")\n",
    "        return\n",
    "    \n",
    "    if not os.path.exists('.git'):\n",
    "        print(\"⚠️ Skipping (not a git repository)\")\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        # Check for M6-related commits in git history\n",
    "        result = subprocess.run(\n",
    "            ['git', 'log', '--oneline', '--all', '--grep=M6'], \n",
    "            capture_output=True, text=True, timeout=5\n",
    "        )\n",
    "        commits = result.stdout.strip().split('\\n') if result.stdout.strip() else []\n",
    "        print(f\"✓ M6 commits found: {len(commits)}\")\n",
    "        \n",
    "        # List modules requiring manual verification\n",
    "        modules = ['M6.1 (PII)', 'M6.2 (Vault)', 'M6.3 (RBAC)', 'M6.4 (Audit)']\n",
    "        for module in modules:\n",
    "            print(f\"  - {module}: Manual verification required\")\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Skipping (git check failed)\")\n",
    "\n",
    "# Uncomment to run: check_m6_completion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 6: Call-Forward to M7.1 - Distributed Tracing\n",
    "\n",
    "### The Gap We're About to Fill\n",
    "\n",
    "**Current State**: Prometheus metrics show aggregate P95 latency of 850ms, but provide **zero visibility** into why individual requests exceed this baseline.\n",
    "\n",
    "**The Problem**: A mysterious 4.2-second query cannot be diagnosed without request-level tracing.\n",
    "\n",
    "### What M7.1 Will Deliver\n",
    "\n",
    "**OpenTelemetry Instrumentation** enabling:\n",
    "\n",
    "1. **Request-Level Timing** (millisecond precision)\n",
    "   - Trace requests through retrieval → reranking → generation stages\n",
    "   - Identify exact bottlenecks in the pipeline\n",
    "\n",
    "2. **Service Dependency Visualization**\n",
    "   - See how failures cascade through the system\n",
    "   - Understand component interactions\n",
    "\n",
    "3. **Production Optimization Evidence**\n",
    "   - Example: Discover OpenAI calls consume 85% of latency\n",
    "   - Enable data-driven model selection decisions\n",
    "\n",
    "### Three Core Capabilities\n",
    "\n",
    "| Capability | Value |\n",
    "|------------|-------|\n",
    "| **Per-Request Breakdown** | Identify which operation causes slowness in each request |\n",
    "| **Cascading Failure Detection** | Visualize how one slow component impacts entire pipeline |\n",
    "| **Jaeger UI** | Interactive trace visualization and analysis |\n",
    "\n",
    "### Module 7 Roadmap (155 minutes total)\n",
    "\n",
    "- **M7.1** (42 min): OpenTelemetry instrumentation - \"Why was THIS query slow?\"\n",
    "- **M7.2** (38 min): Unified observability - Link metrics → logs → traces\n",
    "- **M7.3** (35 min): Performance profiling - CPU/memory hotspots\n",
    "- **M7.4** (40 min): Trace-based SLI monitoring and anomaly detection\n",
    "\n",
    "**Next Step**: Once all readiness checks pass, begin M7.1 to gain request-level visibility into system performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
