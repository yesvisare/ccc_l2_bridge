{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bridge L3.M8.2 ‚Üí L3.M8.3 Readiness Validation\n",
    "\n",
    "**From EXPERIMENTATION TO AUTOMATION**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Purpose\n",
    "\n",
    "M8.2 gave you **manual A/B testing**: traffic splitting, multi-metric tracking, statistical significance, and gradual rollouts. But production systems face 5-10 commits daily from multiple engineers‚Äî**manual testing cannot scale.**\n",
    "\n",
    "M8.3 introduces **automated CI/CD pipelines** that catch regressions before they reach production. This bridge validates you have the foundational infrastructure (golden test sets, Git workflows, containerization, fast tests) needed to automate regression detection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concepts Covered\n",
    "\n",
    "- **Readiness checks** for golden test sets, version control, containerization, and fast test execution\n",
    "- **Offline-friendly validation** with graceful skips when infrastructure is missing\n",
    "- **Call-forward preview** of M8.3 automation capabilities (GitHub Actions, regression baselines, DVC versioning, cost/latency guards)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## After Completing\n",
    "\n",
    "You will be able to:\n",
    "\n",
    "- ‚úÖ Assess which automation prerequisites you already have (golden sets, Git, Docker, fast tests)\n",
    "- ‚úÖ Understand why manual testing breaks at scale (compounding failure scenario)\n",
    "- ‚úÖ Articulate what M8.3 will automate (GitHub Actions, regression detection, model versioning, cost guards)\n",
    "- ‚úÖ Identify gaps to address before implementing CI/CD pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Context in Track\n",
    "\n",
    "**Bridge**: L3.M8.2 ‚Üí L3.M8.3  \n",
    "**Previous**: M8.2 ‚Äî Experimentation (A/B testing, multi-metric evaluation, gradual rollouts)  \n",
    "**Next**: M8.3 ‚Äî Automation (GitHub Actions, regression detection, DVC, cost/latency guards)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Locally\n",
    "\n",
    "**Windows** (PowerShell):  \n",
    "```powershell\n",
    "$env:PYTHONPATH=\"$PWD\"; jupyter notebook Bridge_L3_M8_2_to_M8_3_Readiness.ipynb\n",
    "```\n",
    "\n",
    "**macOS/Linux**:  \n",
    "```bash\n",
    "export PYTHONPATH=$PWD && jupyter notebook Bridge_L3_M8_2_to_M8_3_Readiness.ipynb\n",
    "```\n",
    "\n",
    "**All platforms**: Run **Cell ‚Üí Run All** to execute all checks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 1: M8.2 Recap ‚Äî What You Mastered\n",
    "\n",
    "The previous module (M8.2) equipped you with:\n",
    "\n",
    "### üéØ Traffic Splitting Infrastructure\n",
    "Hash-based user assignment ensures consistent routing:\n",
    "- User A always gets control variant\n",
    "- User B always gets treatment variant\n",
    "- No cross-contamination between experiment groups\n",
    "\n",
    "### üìä Multi-Dimensional Measurement\n",
    "Tracking 7+ simultaneous metrics:\n",
    "- **Quality**: Faithfulness, Answer Relevance, Context Precision/Recall\n",
    "- **Performance**: P95 latency, error rate\n",
    "- **Economics**: Cost per query\n",
    "- **User Satisfaction**: User ratings/feedback\n",
    "\n",
    "### üìà Statistical Significance Testing\n",
    "Run experiments (e.g., chunk size 512 vs. 1024 tokens) with:\n",
    "- P-value calculation to determine significance\n",
    "- Confidence intervals for metric deltas\n",
    "- Sample size planning\n",
    "\n",
    "### üöÄ Gradual Rollout Strategy\n",
    "Canary deployments with instant rollback:\n",
    "- 10% ‚Üí 25% ‚Üí 50% ‚Üí 100% traffic progression\n",
    "- Feature flags for instant rollback\n",
    "- Risk mitigation through staged releases\n",
    "\n",
    "---\n",
    "### üî¥ The Problem Gap: Why M8.3 Matters\n",
    "\n",
    "**Real production failure scenario:**\n",
    "\n",
    "Three independent changes deployed without comprehensive testing created a **compounding failure**:\n",
    "1. Code refactoring introduced a chunking boundary bug\n",
    "2. Embedding model upgrade changed semantic space\n",
    "3. Prompt simplification worked with old embeddings but failed with new ones\n",
    "\n",
    "**Result**: Quality dropped from **4.2/5 to 2.9/5** across 10,000 answers before detection.\n",
    "\n",
    "**Core issue**: A/B testing validates changes individually, but production sees 5-10 commits daily from multiple engineers. **Manual testing cannot scale.**\n",
    "\n",
    "M8.3 introduces **automated CI/CD pipelines** that catch regressions before they reach production."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 2: Readiness Check #1 ‚Äî Golden Test Set with Historical Baseline\n",
    "\n",
    "**Purpose**: Establish a regression detection foundation with ground truth test cases.\n",
    "\n",
    "**Requirements**:\n",
    "- ‚úì 100+ test cases with ground truth answers\n",
    "- ‚úì Baseline RAGAS metrics established (Faithfulness, Answer Relevance, Context Precision, Context Recall)\n",
    "- ‚úì Cases covering common queries, edge cases, and historical failures\n",
    "\n",
    "**Impact if missing**: Cannot detect regressions automatically"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for Golden Test Set\n",
    "\n",
    "Searches common file paths for golden test sets (JSON format). If found, reports test count. Otherwise, prints expected format and skips gracefully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Check for golden test set\n",
    "test_set_paths = ['golden_test_set.json', 'test_data/golden_set.json', 'data/golden_tests.json']\n",
    "golden_set_found = False\n",
    "\n",
    "for path in test_set_paths:\n",
    "    if Path(path).exists():\n",
    "        print(f\"‚úì Found golden test set: {path}\")\n",
    "        with open(path) as f:\n",
    "            data = json.load(f)\n",
    "            count = len(data) if isinstance(data, list) else len(data.get('tests', []))\n",
    "            print(f\"  Test cases: {count}\")\n",
    "            golden_set_found = True\n",
    "            break\n",
    "\n",
    "if not golden_set_found:\n",
    "    print(\"‚ö†Ô∏è Skipping (no golden test set found)\")\n",
    "    print(\"# Expected: golden_test_set.json with 100+ test cases\")\n",
    "    print(\"# Each case: {query, ground_truth, context, expected_metrics}\")\n",
    "\n",
    "# Expected: \n",
    "# ‚úì Found golden test set: golden_test_set.json\n",
    "#   Test cases: 125\n",
    "#   Baseline metrics: Faithfulness=0.89, Answer Relevance=0.91"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 3: Readiness Check #2 ‚Äî Version Control with Git\n",
    "\n",
    "**Purpose**: Enable automated quality checks through version control integration.\n",
    "\n",
    "**Requirements**:\n",
    "- ‚úì Code in GitHub/GitLab repository\n",
    "- ‚úì Pull request workflow (no direct main branch commits)\n",
    "- ‚úì Branch protection rules enabled\n",
    "- ‚úì Git command proficiency\n",
    "\n",
    "**Impact if missing**: Cannot automate quality checks without version control"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Git Repository Status\n",
    "\n",
    "Verifies current directory is a Git repository, checks for remote configuration, and notes that branch protection validation requires GitHub API access (offline-friendly skip)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "# Check Git repository status\n",
    "try:\n",
    "    result = subprocess.run(['git', 'rev-parse', '--is-inside-work-tree'], \n",
    "                          capture_output=True, text=True, cwd=os.getcwd())\n",
    "    if result.returncode == 0:\n",
    "        print(\"‚úì Git repository detected\")\n",
    "        \n",
    "        # Check remote\n",
    "        remote = subprocess.run(['git', 'remote', '-v'], capture_output=True, text=True)\n",
    "        if remote.stdout:\n",
    "            print(f\"‚úì Remote configured: {remote.stdout.splitlines()[0].split()[1]}\")\n",
    "        \n",
    "        # Check branch protection (stub - requires GitHub API)\n",
    "        print(\"‚ö†Ô∏è Branch protection check requires GitHub API token (skipping offline)\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Not a Git repository\")\n",
    "except FileNotFoundError:\n",
    "    print(\"‚ö†Ô∏è Skipping (Git not installed)\")\n",
    "\n",
    "# Expected:\n",
    "# ‚úì Git repository detected\n",
    "# ‚úì Remote configured: git@github.com:org/rag-system.git\n",
    "# ‚ö†Ô∏è Branch protection check requires GitHub API token (skipping offline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 4: Readiness Check #3 ‚Äî Containerized RAG System\n",
    "\n",
    "**Purpose**: Enable CI/CD test execution in isolated, reproducible environments.\n",
    "\n",
    "**Requirements**:\n",
    "- ‚úì Working Dockerfile\n",
    "- ‚úì Successful Docker image builds\n",
    "- ‚úì Tests executable inside container\n",
    "- ‚úì All dependencies specified\n",
    "\n",
    "**Impact if missing**: CI/CD cannot execute tests without containerization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for Dockerfile and Docker Availability\n",
    "\n",
    "Searches common Dockerfile locations. If found, verifies Docker CLI is installed. Does not attempt to build images (offline-friendly)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for Dockerfile\n",
    "dockerfile_paths = ['Dockerfile', 'docker/Dockerfile', '.docker/Dockerfile']\n",
    "dockerfile_found = False\n",
    "\n",
    "for path in dockerfile_paths:\n",
    "    if Path(path).exists():\n",
    "        print(f\"‚úì Found Dockerfile: {path}\")\n",
    "        dockerfile_found = True\n",
    "        break\n",
    "\n",
    "if not dockerfile_found:\n",
    "    print(\"‚ö†Ô∏è Skipping (no Dockerfile found)\")\n",
    "    print(\"# Expected: Dockerfile with test execution stage\")\n",
    "    \n",
    "# Check Docker availability (offline-friendly - version check only)\n",
    "try:\n",
    "    docker_check = subprocess.run(['docker', '--version'], \n",
    "                                 capture_output=True, text=True, timeout=5)\n",
    "    if docker_check.returncode == 0:\n",
    "        print(f\"‚úì Docker available: {docker_check.stdout.strip()}\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Docker not available\")\n",
    "except (FileNotFoundError, subprocess.TimeoutExpired):\n",
    "    print(\"‚ö†Ô∏è Skipping (Docker not installed)\")\n",
    "\n",
    "# Expected:\n",
    "# ‚úì Found Dockerfile: Dockerfile\n",
    "# ‚úì Docker available: Docker version 24.0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 5: Readiness Check #4 ‚Äî Fast Test Execution (<5 minutes)\n",
    "\n",
    "**Purpose**: Prevent CI/CD bottlenecks with rapid feedback loops.\n",
    "\n",
    "**Requirements**:\n",
    "- ‚úì Golden test set runs in <5 minutes\n",
    "- ‚úì Mock expensive external calls (OpenAI, Pinecone)\n",
    "- ‚úì Tests don't require full database setup\n",
    "- ‚úì Local test execution before pushing\n",
    "\n",
    "**Impact if missing**: Slow CI becomes a workaround bottleneck"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check for Test Files and Mocking Libraries\n",
    "\n",
    "Detects test directories/files and verifies mocking capability. Does not execute tests (offline-friendly). Suggests running `pytest --durations=10` to measure test speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Simulate test execution timing check (offline-friendly)\n",
    "test_files = ['tests/', 'test/', 'tests.py', 'test_*.py']\n",
    "test_found = any(Path(p).exists() for p in test_files)\n",
    "\n",
    "if test_found:\n",
    "    print(\"‚úì Test files detected\")\n",
    "    print(\"‚ö†Ô∏è Run 'pytest --durations=10' to check test execution time\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Skipping (no test files found)\")\n",
    "    print(\"# Expected: Test suite completes in <5 minutes\")\n",
    "\n",
    "# Check for mocking libraries\n",
    "try:\n",
    "    import unittest.mock\n",
    "    print(\"‚úì Mocking library available (unittest.mock)\")\n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è Consider adding pytest-mock or unittest.mock\")\n",
    "\n",
    "# Expected:\n",
    "# ‚úì Test files detected\n",
    "# ‚ö†Ô∏è Run 'pytest --durations=10' to check test execution time\n",
    "# ‚úì Mocking library available (unittest.mock)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 6: Call-Forward ‚Äî What M8.3 Will Introduce\n",
    "\n",
    "M8.3 transforms manual testing into **automated regression detection** with four key capabilities:\n",
    "\n",
    "### ü§ñ Capability 1: GitHub Actions Workflow\n",
    "**Automated pipeline triggering on every pull request**:\n",
    "- Builds containers automatically\n",
    "- Runs golden test sets\n",
    "- Calculates RAGAS metrics\n",
    "- Compares against baseline\n",
    "- **Blocks PRs if quality degrades >5%**\n",
    "\n",
    "**Outcome**: No manual intervention needed. Every PR validated before merge.\n",
    "\n",
    "---\n",
    "\n",
    "### üõ°Ô∏è Capability 2: Regression Detection with Baselines\n",
    "**Automatic comparison of current metrics against baseline**:\n",
    "- Blocks PRs with >5 percentage point Faithfulness drops\n",
    "- Blocks PRs with doubled error rates\n",
    "- Real-time quality gates in CI/CD pipeline\n",
    "- Historical trend tracking\n",
    "\n",
    "**Outcome**: Regressions caught in CI, never in production.\n",
    "\n",
    "---\n",
    "\n",
    "### üì¶ Capability 3: Model & Prompt Versioning with DVC\n",
    "**Version control for ML artifacts**:\n",
    "- Embedding models versioned\n",
    "- LLM models versioned\n",
    "- Prompt templates tracked\n",
    "- Golden test sets under version control\n",
    "- **Instant rollback to last-known-good configuration in 2-3 minutes**\n",
    "\n",
    "**Outcome**: Any change is reversible. Zero production risk.\n",
    "\n",
    "---\n",
    "\n",
    "### üí∞ Capability 4: Cost & Latency Regression Detection\n",
    "**Guardian rails for performance and economics**:\n",
    "- Detects cost increases >30%\n",
    "- Detects latency increases >25%\n",
    "- Automated warnings or blocks\n",
    "- Budget protection for production systems\n",
    "\n",
    "**Outcome**: No surprise bills. No performance degradation.\n",
    "\n",
    "---\n",
    "\n",
    "### üéØ The Ultimate Outcome\n",
    "\n",
    "**\"Zero regressions reach production. Every commit validated automatically. Engineers get feedback in 5 minutes.\"**\n",
    "\n",
    "M8.3 shifts the burden from manual testing to automated pipelines, enabling teams to ship faster with higher confidence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary: Readiness Assessment\n",
    "\n",
    "Run all cells above to validate your readiness for M8.3.\n",
    "\n",
    "**Passing Criteria**:\n",
    "- ‚úì At least 2 of 4 checkpoints have infrastructure in place\n",
    "- ‚úì Understanding of why automation matters (problem gap)\n",
    "- ‚úì Clear vision of M8.3 capabilities (call-forward)\n",
    "\n",
    "**Next Steps**:\n",
    "1. Address any ‚ö†Ô∏è warnings from the checks above\n",
    "2. Proceed to **M8.3: From Experimentation to Automation**\n",
    "3. Implement automated CI/CD pipelines with regression detection\n",
    "\n",
    "**Bridge Complete** ‚úÖ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
